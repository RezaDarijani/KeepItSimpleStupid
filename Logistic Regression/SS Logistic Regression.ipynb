{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e656c3f-4d13-4843-872d-aeecf81960e4",
   "metadata": {},
   "source": [
    "# Simple, Stupid implementation of logistic regression\n",
    "by: Seyed Reza Darijani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c028f475-07c5-4365-a136-8769023f751d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9fb792-213c-49b4-9ce0-af86e216c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"defining sigmoid function for activation function\"\"\"\n",
    "    return (1/(1+np.exp(-z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8a452-30d6-4640-bcd8-c2280b106210",
   "metadata": {},
   "source": [
    "### A very Simple Dataset\n",
    "(three numbers as inputs and if the sum is >= 9 then output is (1) else output is (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e6452a-58ca-41dc-a81e-6cb18649e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      " [[3. 2. 3. ... 4. 3. 1.]\n",
      " [3. 2. 3. ... 5. 1. 3.]\n",
      " [4. 3. 6. ... 4. 1. 1.]]\n",
      "\n",
      "outputs:\n",
      " [[1. 0. 1. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#loading first three columns as inputs (5000,3) and transpose it (3,5000)\n",
    "x = np.loadtxt('train_set.csv', usecols=(0,1,2), delimiter=',').T\n",
    "\n",
    "#loading fourth column as output (5000,)(1d array) and reshape it (1,5000)(2d array)\n",
    "y = np.loadtxt('train_set.csv', usecols=(3,), delimiter=',').reshape(1,5000)\n",
    "\n",
    "print('inputs:\\n',x)\n",
    "print('\\noutputs:\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55faf215-ffc8-4253-99b8-42446d5ffc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initial weights:\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "initial bias:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "#initial weights and bias\n",
    "w = np.zeros((3,1))\n",
    "b = 0\n",
    "\n",
    "print('\\ninitial weights:\\n',w)\n",
    "print('\\ninitial bias:\\n',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446352f5-4ec6-48d8-9004-0c0c8c50d175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training weights:\n",
      " [[2.34308783]\n",
      " [2.32703968]\n",
      " [2.32214983]]\n",
      "\n",
      "after training bias:\n",
      " -19.612496736794892\n"
     ]
    }
   ],
   "source": [
    "#learning rate\n",
    "alpha = 0.5\n",
    "\n",
    "# 3968 iteration for _gradient descent_ convex optimization technique\n",
    "for i in range(3968):\n",
    "    \n",
    "    #forward propagation\n",
    "    z = np.matmul(w.T, x)+b\n",
    "    a = sigmoid(z)\n",
    "    \n",
    "    #backward propagation\n",
    "    dz = a-y\n",
    "    dw = (x * dz).sum(axis=1, keepdims=True) / 5000\n",
    "    db = dz.sum() / 5000\n",
    "    tempw = w - alpha*dw\n",
    "    tempb = b - alpha*db\n",
    "    w = tempw\n",
    "    b = tempb\n",
    "    \n",
    "    \n",
    "#print results   \n",
    "print('after training weights:\\n',w)\n",
    "print('\\nafter training bias:\\n',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8760ba-ad6c-448c-ab7e-8b0eed006fe5",
   "metadata": {},
   "source": [
    ">Feel free to reRUN the cell above multiple times or with different iteration number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c874479-2854-46ba-9011-8527afff9ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sum of difference between all labeled outputs and our model outputs:\n",
      " 19.643407287296405\n"
     ]
    }
   ],
   "source": [
    "print('\\nsum of difference between all labeled outputs and our model outputs:\\n',dz.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cff8f4-2e9f-4583-b80c-e3ba0853c638",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Note:\n",
    "the differnce between our model 5000 outputs(Matrix a(1,5000)) and real outputs(Matrix y(1,5000)) smoothly go near zero.  \n",
    "actually with more iteration, it will be more near zero.  \n",
    ">Logestic regression like the perceptron is a linear classifier, therefore it will never get to the state with all the input vectors classified correctly if the training set  is not linearly separable.  \n",
    "https://en.wikipedia.org/wiki/Perceptron#Convergence\n",
    "\n",
    ">__but__ _our training set is linearly separable_.(three numbers as inputs and if the sum is >= 9 then output is (1) else output is (0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47d14d-5e07-4f71-850e-9467a31d994f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf11c63b-c41a-4a62-a8c0-ba923cd7b597",
   "metadata": {
    "tags": []
   },
   "source": [
    "# using scikit-learn package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f2998-c79f-4e17-8973-2c0a2256764d",
   "metadata": {},
   "source": [
    "scikit-learn results are in accordance with our model with __learning rate (alpha=0.5)__ and __3968 iteration__ approximately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d947fcbb-b8f8-479c-b7c3-84e13157eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-19.61286299]\n",
      "[[2.34308311 2.32708229 2.32219568]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#loading fourth column as output (5000,)(1d array)\n",
    "y = np.loadtxt('train_set.csv', usecols=(3,), delimiter=',')\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "model.fit(x.T, y)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22551287-ac7c-4f6b-b942-bddcfaf04086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.02764183e-01, 7.97235817e-01],\n",
       "       [2.26624652e-05, 9.99977338e-01],\n",
       "       [2.00973495e-01, 7.99026505e-01],\n",
       "       ...,\n",
       "       [2.28336394e-06, 9.99997717e-01],\n",
       "       [2.29938484e-04, 9.99770062e-01],\n",
       "       [2.45979091e-02, 9.75402091e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(np.loadtxt('test_set.csv', usecols=(0,1,2), delimiter=','))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
